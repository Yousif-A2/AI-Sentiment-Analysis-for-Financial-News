{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                           Sentence\n",
       "0          0  According to Gran , the company has no plans t...\n",
       "1          1  For the last quarter of 2010 , Componenta 's n...\n",
       "2          1  In the third quarter of 2010 , net sales incre...\n",
       "3          1  Operating profit rose to EUR 13.1 mn from EUR ...\n",
       "4          1  Operating profit totalled EUR 21.1 mn , up fro..."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Sentiment_Stock_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108751"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment    0\n",
       "Sentence     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the existence of NaN values in a cell:\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108750"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect & remove empty strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 blanks:  []\n"
     ]
    }
   ],
   "source": [
    "blanks = []  # start with an empty list\n",
    "\n",
    "for i,lb,rv in df.itertuples():  # iterate over the DataFrame\n",
    "    if type(rv)==str:            # avoid NaN values\n",
    "        if rv.isspace():         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "        \n",
    "print(len(blanks), 'blanks: ', blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108750"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a quick look at the `label` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    55724\n",
       "0    53026\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train & test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Sentence']\n",
    "y = df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    according to gran   the company has no plans t...\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuations\n",
    "X.replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n",
    "\n",
    "for index in X:\n",
    "    X=X.str.lower()\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pipelines \n",
    "In this step we will create a pipeline to vectorize the data, then train and fit a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Naïve Bayes:\n",
    "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Naïve Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Form a prediction set\n",
    "predictions = text_clf_nb.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3157 4789]\n",
      " [2792 5575]]\n"
     ]
    }
   ],
   "source": [
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.40      0.45      7946\n",
      "           1       0.54      0.67      0.60      8367\n",
      "\n",
      "    accuracy                           0.54     16313\n",
      "   macro avg       0.53      0.53      0.52     16313\n",
      "weighted avg       0.53      0.54      0.53     16313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5352786121498192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_lsvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3990 3956]\n",
      " [3673 4694]]\n"
     ]
    }
   ],
   "source": [
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.50      0.51      7946\n",
      "           1       0.54      0.56      0.55      8367\n",
      "\n",
      "    accuracy                           0.53     16313\n",
      "   macro avg       0.53      0.53      0.53     16313\n",
      "weighted avg       0.53      0.53      0.53     16313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5323361736038742\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn's built-in list stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'among', 'show', 'fire', 'from', 'almost', 'inc', 'per', 'towards', 'latter', 'he', 'have', 'whereas', 'eleven', 'front', 'forty', 'meanwhile', 'i', 'an', 'any', 'thence', 'has', 'about', 'seem', 'every', 'now', 'ltd', 'done', 'became', 'own', 'thru', 'part', 'always', 'thin', 'the', 'side', 'not', 'which', 'her', 'give', 'go', 'but', 'thereby', 'afterwards', 'very', 'wherever', 'she', 'mine', 'myself', 'or', 'seeming', 'six', 'across', 'himself', 'somewhere', 'enough', 'also', 'whence', 'sometimes', 'hasnt', 'on', 'nowhere', 'full', 'before', 'sincere', 'its', 'must', 'nobody', 'wherein', 'nine', 'being', 'move', 'herself', 'namely', 'above', 'if', 'becoming', 'beforehand', 'nothing', 'yourselves', 'only', 'within', 'over', 'both', 'perhaps', 'him', 'everywhere', 'sometime', 'take', 'everyone', 'his', 'is', 'elsewhere', 'below', 'everything', 'whose', 'cant', 'well', 'hundred', 'someone', 'whereupon', 'that', 'amoungst', 'two', 'sixty', 'those', 'will', 'with', 'this', 'thereupon', 'many', 'each', 'several', 'herein', 'their', 'else', 'all', 'other', 'twelve', 'none', 'name', 'either', 'out', 'whereafter', 'three', 'had', 'do', 'us', 'anywhere', 'whom', 'same', 'yours', 'after', 'keep', 'rather', 'etc', 'further', 'call', 'we', 'once', 'hereby', 'why', 'together', 'up', 'than', 'such', 'of', 'cannot', 'couldnt', 'behind', 'alone', 'hers', 'along', 'anyhow', 'fifty', 'without', 'thus', 'serious', 'thereafter', 'more', 'in', 'while', 'whereby', 'top', 'something', 'mill', 'however', 'they', 'made', 'may', 'bill', 'ie', 'noone', 'empty', 'via', 'please', 'whatever', 'indeed', 'am', 'mostly', 'cry', 'twenty', 'anyone', 'these', 'since', 'some', 'de', 'at', 'anything', 'down', 'then', 'although', 'moreover', 'one', 'there', 'interest', 'neither', 'when', 'others', 'until', 'never', 'between', 'onto', 're', 'against', 'therefore', 'could', 'itself', 'third', 'though', 'were', 'me', 'whether', 'your', 'would', 'what', 'fill', 'find', 'otherwise', 'a', 'get', 'last', 'ten', 'who', 'as', 'latterly', 'fifteen', 'see', 'themselves', 'formerly', 'how', 'whither', 'often', 'into', 'next', 'detail', 'anyway', 'nor', 'therein', 'be', 'eg', 'seems', 'and', 'become', 'describe', 'because', 'becomes', 'seemed', 'whenever', 'again', 'back', 'toward', 'ourselves', 'still', 'might', 'was', 'where', 'nevertheless', 'few', 'beyond', 'least', 'them', 'hereafter', 'former', 'can', 'it', 'our', 'put', 'beside', 'amongst', 'un', 'four', 'co', 'due', 'yet', 'too', 'here', 'for', 'been', 'somehow', 'hereupon', 'except', 'ever', 'are', 'bottom', 'off', 'even', 'con', 'through', 'whole', 'five', 'amount', 'should', 'thick', 'throughout', 'whoever', 'you', 'yourself', 'by', 'less', 'found', 'system', 'during', 'first', 'another', 'most', 'eight', 'my', 'under', 'ours', 'to', 'so', 'much', 'upon', 'hence', 'already', 'no', 'around', 'besides'})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "print(text.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a', 'about', 'an', 'and', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', \\\n",
    "             'even', 'ever', 'for', 'from', 'get', 'had', 'has', 'have', 'he', 'her', 'hers', 'his', \\\n",
    "             'how', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'me', 'my', 'of', 'on', 'or', \\\n",
    "             'see', 'seen', 'she', 'so', 'than', 'that', 'the', 'their', 'there', 'they', 'this', \\\n",
    "             'to', 'was', 'we', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(stop_words=['a', 'about', 'an', 'and', 'are',\n",
       "                                             'as', 'at', 'be', 'been', 'but',\n",
       "                                             'by', 'can', 'even', 'ever', 'for',\n",
       "                                             'from', 'get', 'had', 'has',\n",
       "                                             'have', 'he', 'her', 'hers', 'his',\n",
       "                                             'how', 'i', 'if', 'in', 'into',\n",
       "                                             'is', ...])),\n",
       "                ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL TO ADD STOPWORDS TO THE LINEAR SVC PIPELINE:\n",
    "text_clf_nb2 = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "text_clf_nb2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3999 3947]\n",
      " [3672 4695]]\n"
     ]
    }
   ],
   "source": [
    "predictions = text_clf_nb2.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.50      0.51      7946\n",
      "           1       0.54      0.56      0.55      8367\n",
      "\n",
      "    accuracy                           0.53     16313\n",
      "   macro avg       0.53      0.53      0.53     16313\n",
      "weighted avg       0.53      0.53      0.53     16313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5329491816342794\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed new data into a trained model\n",
    "Once we've developed a fairly accurate model, it's time to feed new data through it. In this last section we'll write our own news, and see how accurately our model assigns a \"positive\" or \"negative\" label to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feed new data to the model's `predict()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "myreview = \"Wall Street closed modestly lower on Monday, adding to last week's sharp losses on nagging concerns about the Federal Reserve's determination to aggressively hike interest rates to fight inflation even as the economy slows.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(text_clf_lsvc.predict([myreview]))  # be sure to put \"myreview\" inside square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "myreview = \"European markets were lower on Monday after U.S. Federal Reserve Chair Jerome Powell signaled higher interest rates would likely persist in a bid to tame soaring inflation. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=text_clf_nb.predict([myreview])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Full_Data1_modelEUR']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "joblib.dump(text_clf_nb,\"Naive Bayes_model\")\n",
    "#text_clf_nb = joblib.load(\"1modelEUR.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
